{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting nltk\n",
      "  Using cached nltk-3.6.7-py3-none-any.whl (1.5 MB)\n",
      "Requirement already satisfied: joblib in /Users/marcuscorreia/opt/anaconda3/envs/fake_news2/lib/python3.10/site-packages (from nltk) (1.1.0)\n",
      "Requirement already satisfied: tqdm in /Users/marcuscorreia/opt/anaconda3/envs/fake_news2/lib/python3.10/site-packages (from nltk) (4.62.3)\n",
      "Collecting regex>=2021.8.3\n",
      "  Downloading regex-2022.1.18-cp310-cp310-macosx_10_9_x86_64.whl (288 kB)\n",
      "\u001b[K     |████████████████████████████████| 288 kB 4.7 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: click in /Users/marcuscorreia/opt/anaconda3/envs/fake_news2/lib/python3.10/site-packages (from nltk) (8.0.3)\n",
      "Installing collected packages: regex, nltk\n",
      "Successfully installed nltk-3.6.7 regex-2022.1.18\n"
     ]
    }
   ],
   "source": [
    "!pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import spacy\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "import string\n",
    "import pickle\n",
    "from sklearn import model_selection\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/marcuscorreia/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "news = pd.read_csv(\"Data/final_news.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "news.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "news[\"corpus\"] = news[\"Article_title\"] +\" \" +news[\"Article_body\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Article_title</th>\n",
       "      <th>Article_body</th>\n",
       "      <th>Title_length</th>\n",
       "      <th>Body_length</th>\n",
       "      <th>Target</th>\n",
       "      <th>Number_of_tweets</th>\n",
       "      <th>corpus</th>\n",
       "      <th>corpus_length_original</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>The Battle of New York: Why This Primary Matters</td>\n",
       "      <td>It's primary day in New York and front-runners...</td>\n",
       "      <td>9.0</td>\n",
       "      <td>317.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>The Battle of New York: Why This Primary Matte...</td>\n",
       "      <td>205.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13</td>\n",
       "      <td>Trump takes on Cruz, but lightly</td>\n",
       "      <td>Killing Obama administration rules, dismantlin...</td>\n",
       "      <td>6.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Trump takes on Cruz, but lightly Killing Obama...</td>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Unnamed: 0                                     Article_title  \\\n",
       "0          4  The Battle of New York: Why This Primary Matters   \n",
       "1         13                  Trump takes on Cruz, but lightly   \n",
       "\n",
       "                                        Article_body  Title_length  \\\n",
       "0  It's primary day in New York and front-runners...           9.0   \n",
       "1  Killing Obama administration rules, dismantlin...           6.0   \n",
       "\n",
       "   Body_length  Target Number_of_tweets  \\\n",
       "0        317.0     0.0              0.0   \n",
       "1         17.0     0.0              0.0   \n",
       "\n",
       "                                              corpus  corpus_length_original  \n",
       "0  The Battle of New York: Why This Primary Matte...                   205.0  \n",
       "1  Trump takes on Cruz, but lightly Killing Obama...                    16.0  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = news[\"corpus\"]\n",
    "y = news[\"Target\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data into train/test\n",
    "x_train, x_test, y_train, y_test = train_test_split(x,y,test_size = 0.4,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tfidif vectorizer\n",
    "vectorizor = TfidfVectorizer(stop_words = \"english\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit and transform to dataset\n",
    "vec_x_train = vectorizor.fit_transform(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<9833x78841 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 1506632 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizor.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['00', '000', '0000', ..., 'zzn3bqnfsk', 'zzucqevt3m', 'zzzzzzzz'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizor.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "vec_x_test = vectorizor.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "vec_x_test = vectorizor.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a logistic regression classifier\n",
    "log_reg_Classifier = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit the data\n",
    "log_reg_Classifier.fit(vec_x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(vectorizor, open(\"Model_files/Vectorisors/log_reg_vec.pkl\", 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(log_reg_Classifier, open(\"Model_files/Models/log_reg_model.pkl\", 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove non ascii characters\n",
    "def remove_non_ascii(word):\n",
    "    new_word = word.encode(\"ascii\",\"ignore\").decode()\n",
    "    return new_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_input(input):\n",
    "    # remove punctuation and stop\n",
    "    # load language model\n",
    "    sp = spacy.load('en_core_web_sm')\n",
    "    # import stop words\n",
    "    all_stopwords = sp.Defaults.stop_words\n",
    "    # import puncuation\n",
    "    punc  = string.punctuation\n",
    "\n",
    "    # replace any weird characters\n",
    "    text = input\n",
    "    remove_non_ascii(text)\n",
    "\n",
    "    # remove puncuation\n",
    "    new_text = text.translate(str.maketrans('', '', punc))\n",
    "\n",
    "    # tokenize and make everything lower case\n",
    "    text_tokens = word_tokenize(new_text.lower())\n",
    "\n",
    "    # remove stop words\n",
    "    tokens_without_sw= [word for word in text_tokens if not word in all_stopwords]\n",
    "\n",
    "    # make list a string again\n",
    "    tokens_without_sw = \" \".join(tokens_without_sw)\n",
    "    tokens_without_sw\n",
    "\n",
    "    return str(tokens_without_sw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all are from abc news\n",
    "# # this predicts 0\n",
    "# test_string = \"\"\"WA health authorities urge anyone with COVID symptoms to get tested and isolate, as state records seven new cases\"\"\"\n",
    "\n",
    "# # this predicts 0\n",
    "# test_string = \"\"\"Passenger killed in fiery crash in Adelaide's north, police investigate shooting between cars\"\"\"\n",
    "\n",
    "# # this predicts 0\n",
    "# test_string = \"\"\"Environmentalists vow to fight latest Kimberley fracking proposal to unearth Australia's largest oil resource\"\"\"\n",
    "\n",
    "## this predicts 1\n",
    "# test_string = \"\"\"How Facebook Fact-checking Can Backfire\"\"\" \n",
    "\n",
    "## this predicts 1\n",
    "test_string = \"\"\"Hulk Sad! Tatiana Maslany Says She Is Not Playing She-Hulk\"\"\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_string = test_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test on the test data (this is testing on multiple article titles at once)\n",
    "log_reg_vec_m = vectorizor.transform(x_test.tolist())\n",
    "\n",
    "# test on random article title\n",
    "log_reg_vec = vectorizor.transform([test_string])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predicted values of each test article\n",
    "predictions_m = log_reg_Classifier.predict(log_reg_vec_m)\n",
    "\n",
    "# predicted values of random test article\n",
    "predictions = log_reg_Classifier.predict(log_reg_vec)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 1. 1. ... 1. 0. 0.]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print out result\n",
    "print(predictions_m)\n",
    "\n",
    "# print out result\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predictions</th>\n",
       "      <th>Actual</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2350</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2756342</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2754595</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2754230</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2754986</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1836910</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10854</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1838237</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9364</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7535</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9833 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Predictions  Actual\n",
       "2350             0.0     0.0\n",
       "2756342          1.0     1.0\n",
       "2754595          1.0     1.0\n",
       "2754230          1.0     1.0\n",
       "2754986          1.0     1.0\n",
       "...              ...     ...\n",
       "1836910          1.0     1.0\n",
       "10854            0.0     0.0\n",
       "1838237          1.0     1.0\n",
       "9364             0.0     0.0\n",
       "7535             0.0     0.0\n",
       "\n",
       "[9833 rows x 2 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z = pd.DataFrame({\"Predictions\":predictions_m,\"Actual\":y_test})\n",
    "z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data Score: 0.981217792243016\n",
      "Testing Data Score: 0.9701006813790298\n"
     ]
    }
   ],
   "source": [
    "print(f\"Training Data Score: {log_reg_Classifier.score(vec_x_train, y_train)}\")\n",
    "print(f\"Testing Data Score: {log_reg_Classifier.score(vec_x_test, y_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(294, 2)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# show how many are not correct\n",
    "z[z.Predictions != z.Actual].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load vectoriser\n",
    "LR_vec = pickle.load( open(\"Model_files/Vectorisors/log_reg_vec.pkl\",\"rb\"))\n",
    "# load model\n",
    "LR_model = pickle.load(open(\"Model_files/Models/log_reg_model.pkl\", 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.969 (0.005)\n"
     ]
    }
   ],
   "source": [
    "# using accuracy\n",
    "kfold = model_selection.KFold(n_splits=10, random_state=7, shuffle=True)\n",
    "scoring = 'accuracy'\n",
    "results = model_selection.cross_val_score(LR_model, vec_x_train, y_train, cv=kfold, scoring=scoring)\n",
    "print(\"Accuracy: %.3f (%.3f)\" % (results.mean(), results.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.994 (0.002)\n"
     ]
    }
   ],
   "source": [
    "# using roc\n",
    "kfold = model_selection.KFold(n_splits=10, random_state=7, shuffle=True)\n",
    "scoring = 'roc_auc'\n",
    "results = model_selection.cross_val_score(LR_model, vec_x_train, y_train, cv=kfold, scoring=scoring)\n",
    "print(\"Accuracy: %.3f (%.3f)\" % (results.mean(), results.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "X has 78841 features, but LogisticRegression is expecting 77705 features as input.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [42]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# using confusion matrix\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m predicted2 \u001b[38;5;241m=\u001b[39m \u001b[43mLR_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvec_x_test\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m matrix \u001b[38;5;241m=\u001b[39m confusion_matrix(y_test, predicted2)\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(matrix)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/fake_news2/lib/python3.10/site-packages/sklearn/linear_model/_base.py:425\u001b[0m, in \u001b[0;36mLinearClassifierMixin.predict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    411\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpredict\u001b[39m(\u001b[38;5;28mself\u001b[39m, X):\n\u001b[1;32m    412\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    413\u001b[0m \u001b[38;5;124;03m    Predict class labels for samples in X.\u001b[39;00m\n\u001b[1;32m    414\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    423\u001b[0m \u001b[38;5;124;03m        Vector containing the class labels for each sample.\u001b[39;00m\n\u001b[1;32m    424\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 425\u001b[0m     scores \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecision_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    426\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(scores\u001b[38;5;241m.\u001b[39mshape) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    427\u001b[0m         indices \u001b[38;5;241m=\u001b[39m (scores \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mint\u001b[39m)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/fake_news2/lib/python3.10/site-packages/sklearn/linear_model/_base.py:407\u001b[0m, in \u001b[0;36mLinearClassifierMixin.decision_function\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    387\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    388\u001b[0m \u001b[38;5;124;03mPredict confidence scores for samples.\u001b[39;00m\n\u001b[1;32m    389\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    403\u001b[0m \u001b[38;5;124;03m    this class would be predicted.\u001b[39;00m\n\u001b[1;32m    404\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    405\u001b[0m check_is_fitted(\u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m--> 407\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcsr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    408\u001b[0m scores \u001b[38;5;241m=\u001b[39m safe_sparse_dot(X, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcoef_\u001b[38;5;241m.\u001b[39mT, dense_output\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m) \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mintercept_\n\u001b[1;32m    409\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m scores\u001b[38;5;241m.\u001b[39mravel() \u001b[38;5;28;01mif\u001b[39;00m scores\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m scores\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/fake_news2/lib/python3.10/site-packages/sklearn/base.py:585\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[0;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[1;32m    582\u001b[0m     out \u001b[38;5;241m=\u001b[39m X, y\n\u001b[1;32m    584\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m check_params\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mensure_2d\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[0;32m--> 585\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_check_n_features\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    587\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/fake_news2/lib/python3.10/site-packages/sklearn/base.py:400\u001b[0m, in \u001b[0;36mBaseEstimator._check_n_features\u001b[0;34m(self, X, reset)\u001b[0m\n\u001b[1;32m    397\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m    399\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n_features \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_features_in_:\n\u001b[0;32m--> 400\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    401\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX has \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mn_features\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m features, but \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    402\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mis expecting \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_features_in_\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m features as input.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    403\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: X has 78841 features, but LogisticRegression is expecting 77705 features as input."
     ]
    }
   ],
   "source": [
    "# using confusion matrix\n",
    "predicted2 = LR_model.predict(vec_x_test)\n",
    "matrix = confusion_matrix(y_test, predicted2)\n",
    "print(matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Top 20 fake\n",
    "top20_fake = sorted(zip(log_reg_Classifier.coef_[0], vectorizor.get_feature_names_out()), reverse=True)[:20]\n",
    "top20_fake= pd.DataFrame(top20_fake, columns=[\"Contribution\",\"Word\"])\n",
    "top20_fake.to_csv(\"Data/contribution_top20_fake.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Contribution</th>\n",
       "      <th>Word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6.059114</td>\n",
       "      <td>video</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.426573</td>\n",
       "      <td>image</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.093540</td>\n",
       "      <td>trump</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.079294</td>\n",
       "      <td>just</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.991160</td>\n",
       "      <td>featured</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3.782185</td>\n",
       "      <td>read</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3.599880</td>\n",
       "      <td>hillary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3.477646</td>\n",
       "      <td>like</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>3.400683</td>\n",
       "      <td>watch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>3.317268</td>\n",
       "      <td>getty</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>3.268420</td>\n",
       "      <td>obama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>3.256350</td>\n",
       "      <td>american</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>3.200412</td>\n",
       "      <td>com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>3.107964</td>\n",
       "      <td>images</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2.932620</td>\n",
       "      <td>america</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2.658261</td>\n",
       "      <td>twitter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2.592425</td>\n",
       "      <td>know</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2.432120</td>\n",
       "      <td>pic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2.393404</td>\n",
       "      <td>wire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2.318382</td>\n",
       "      <td>mr</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Contribution      Word\n",
       "0       6.059114     video\n",
       "1       5.426573     image\n",
       "2       5.093540     trump\n",
       "3       5.079294      just\n",
       "4       4.991160  featured\n",
       "5       3.782185      read\n",
       "6       3.599880   hillary\n",
       "7       3.477646      like\n",
       "8       3.400683     watch\n",
       "9       3.317268     getty\n",
       "10      3.268420     obama\n",
       "11      3.256350  american\n",
       "12      3.200412       com\n",
       "13      3.107964    images\n",
       "14      2.932620   america\n",
       "15      2.658261   twitter\n",
       "16      2.592425      know\n",
       "17      2.432120       pic\n",
       "18      2.393404      wire\n",
       "19      2.318382        mr"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top20_fake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Top 20 real\n",
    "top20_real = sorted(zip(log_reg_Classifier.coef_[0], vectorizor.get_feature_names_out()))[:20]\n",
    "top20_real= pd.DataFrame(top20_real, columns=[\"Contribution\",\"Word\"])\n",
    "top20_real.to_csv(\"Data/contribution_top20_words_real.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Contribution</th>\n",
       "      <th>Word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-13.580728</td>\n",
       "      <td>reuters</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-13.272205</td>\n",
       "      <td>said</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-3.968982</td>\n",
       "      <td>tuesday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-3.662648</td>\n",
       "      <td>minister</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-3.605983</td>\n",
       "      <td>thursday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-3.490588</td>\n",
       "      <td>monday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>-3.403684</td>\n",
       "      <td>friday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>-3.334349</td>\n",
       "      <td>wednesday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>-2.984265</td>\n",
       "      <td>washington</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>-2.837504</td>\n",
       "      <td>government</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>-2.650279</td>\n",
       "      <td>parliament</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>-2.333653</td>\n",
       "      <td>party</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>-2.279345</td>\n",
       "      <td>eu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>-2.249182</td>\n",
       "      <td>killed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>-2.225412</td>\n",
       "      <td>told</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>-2.224185</td>\n",
       "      <td>opposition</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>-2.182595</td>\n",
       "      <td>spokesman</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>-2.173254</td>\n",
       "      <td>london</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>-2.171991</td>\n",
       "      <td>moscow</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>-2.154522</td>\n",
       "      <td>prime</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Contribution        Word\n",
       "0     -13.580728     reuters\n",
       "1     -13.272205        said\n",
       "2      -3.968982     tuesday\n",
       "3      -3.662648    minister\n",
       "4      -3.605983    thursday\n",
       "5      -3.490588      monday\n",
       "6      -3.403684      friday\n",
       "7      -3.334349   wednesday\n",
       "8      -2.984265  washington\n",
       "9      -2.837504  government\n",
       "10     -2.650279  parliament\n",
       "11     -2.333653       party\n",
       "12     -2.279345          eu\n",
       "13     -2.249182      killed\n",
       "14     -2.225412        told\n",
       "15     -2.224185  opposition\n",
       "16     -2.182595   spokesman\n",
       "17     -2.173254      london\n",
       "18     -2.171991      moscow\n",
       "19     -2.154522       prime"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top20_real"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "493f12d9da97b462b23cdf6d969f0de37d476760406272d01afc8d67ae0e197c"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('fake_news': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
